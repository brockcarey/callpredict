{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ec53eb",
   "metadata": {},
   "source": [
    "### DSC 4320 Final Project\n",
    "Brock Carey, Emily Liau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2fb1e7",
   "metadata": {},
   "source": [
    "**Environment Set-Up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceeeb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import category_encoders as ce\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cbb954",
   "metadata": {},
   "source": [
    "**Data Pre-Processing: Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a7775",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import data into environment\n",
    "data = pd.read_csv('C:/Users/bacar/4320/Final Project/callpredict/data.csv', sep=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b74565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types of columns\n",
    "data_types = data.dtypes\n",
    "data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4edcfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert 'DATE_FOR' from object to datetime format\n",
    "data['DATE_FOR'] = pd.to_datetime(data['DATE_FOR'])\n",
    "data['YEAR'] = data['DATE_FOR'].dt.year\n",
    "data['MONTH'] = data['DATE_FOR'].dt.month\n",
    "data['DAY'] = data['DATE_FOR'].dt.day\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c3b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'DATE_FOR' column from dataframe to prevent redundancy\n",
    "data.drop('DATE_FOR', axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e13938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize class imbalance in target variable\n",
    "call_flag_counts = data['Call_Flag'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(call_flag_counts, labels=call_flag_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Class Imbalance in Call_Flag Column')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify categorical variables\n",
    "categorical_vars = [var for var in data.columns if data[var].dtype == 'O']\n",
    "print(\"There are {} categorical variables.\".format(len(categorical_vars)))\n",
    "print(\"The categorical variables are: \", categorical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62224a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check frequency counts of categorical variables\n",
    "for var in categorical_vars:\n",
    "    print(data[var].value_counts())\n",
    "    print(data[var].value_counts() / float(len(data)))\n",
    "    print(var, \" contains \", len(data[var].unique()), \" labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98400afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the presence of NA values in categorical variables\n",
    "print(data[categorical_vars].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566da32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify numerical variables\n",
    "numerical_vars = [var for var in data.columns if data[var].dtype != 'O']\n",
    "print(\"There are {} numerical variables.\".format(len(numerical_vars)))\n",
    "print(\"The numerical variables are: \", numerical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ccc5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the presence of NA values in numerical variables\n",
    "print(data[numerical_vars].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65411eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers in numerical variables\n",
    "print(round(data[numerical_vars].describe()), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize outliers in numerical variables\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(5,5,1)\n",
    "fig = data.boxplot(column='Tenure')\n",
    "fig.set_ylabel('Tenure')\n",
    "\n",
    "plt.subplot(5,5,2)\n",
    "fig = data.boxplot(column='Age')\n",
    "fig.set_ylabel('Age')\n",
    "\n",
    "plt.subplot(5,5,3)\n",
    "fig = data.boxplot(column='CHANNEL1_6M')\n",
    "fig.set_ylabel('CHANNEL1_6M')\n",
    "\n",
    "plt.subplot(5,5,4)\n",
    "fig = data.boxplot(column='CHANNEL2_6M')\n",
    "fig.set_ylabel('CHANNEL2_6M')\n",
    "\n",
    "plt.subplot(5,5,5)\n",
    "fig = data.boxplot(column='CHANNEL3_6M')\n",
    "fig.set_ylabel('CHANNEL3_6M')\n",
    "\n",
    "plt.subplot(5,5,6)\n",
    "fig = data.boxplot(column='CHANNEL4_6M')\n",
    "fig.set_ylabel('CHANNEL4_6M')\n",
    "\n",
    "plt.subplot(5,5,7)\n",
    "fig = data.boxplot(column='CHANNEL5_6M')\n",
    "fig.set_ylabel('CHANNEL5_6M')\n",
    "\n",
    "plt.subplot(5,5,8)\n",
    "fig = data.boxplot(column='METHOD1_6M')\n",
    "fig.set_ylabel('METHOD1_6M')\n",
    "\n",
    "plt.subplot(5,5,9)\n",
    "fig = data.boxplot(column='RECENT_PAYMENT')\n",
    "fig.set_ylabel('RECENT_PAYMENT')\n",
    "\n",
    "plt.subplot(5,5,10)\n",
    "fig = data.boxplot(column='PAYMENTS_6M')\n",
    "fig.set_ylabel('PAYMENTS_6M')\n",
    "\n",
    "plt.subplot(5,5,11)\n",
    "fig = data.boxplot(column='CHANNEL1_3M')\n",
    "fig.set_ylabel('CHANNEL1_3M')\n",
    "\n",
    "plt.subplot(5,5,12)\n",
    "fig = data.boxplot(column='CHANNEL2_3M')\n",
    "fig.set_ylabel('CHANNEL2_3M')\n",
    "\n",
    "plt.subplot(5,5,13)\n",
    "fig = data.boxplot(column='CHANNEL3_3M')\n",
    "fig.set_ylabel('CHANNEL3_3M')\n",
    "\n",
    "plt.subplot(5,5,14)\n",
    "fig = data.boxplot(column='CHANNEL4_3M')\n",
    "fig.set_ylabel('CHANNEL4_3M')\n",
    "\n",
    "plt.subplot(5,5,15)\n",
    "fig = data.boxplot(column='CHANNEL5_3M')\n",
    "fig.set_ylabel('CHANNEL5_3M')\n",
    "\n",
    "plt.subplot(5,5,16)\n",
    "fig = data.boxplot(column='METHOD1_3M')\n",
    "fig.set_ylabel('METHOD1_3M')\n",
    "\n",
    "plt.subplot(5,5,17)\n",
    "fig = data.boxplot(column='PAYMENTS_3M')\n",
    "fig.set_ylabel('PAYMENTS_3M')\n",
    "\n",
    "plt.subplot(5,5,18)\n",
    "fig = data.boxplot(column='NOT_DI_3M')\n",
    "fig.set_ylabel('NOT_DI_3M')\n",
    "\n",
    "plt.subplot(5,5,19)\n",
    "fig = data.boxplot(column='NOT_DI_6M')\n",
    "fig.set_ylabel('NOT_DI_6M')\n",
    "\n",
    "plt.subplot(5,5,20)\n",
    "fig = data.boxplot(column='EVENT2_90_SUM')\n",
    "fig.set_ylabel('EVENT2_90_SUM')\n",
    "\n",
    "plt.subplot(5,5,21)\n",
    "fig = data.boxplot(column='LOGINS')\n",
    "fig.set_ylabel('LOGINS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59c138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# identify columns with NA values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176cd1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply median imputation on NA values for all relevant columns\n",
    "na_cols = ['CHANNEL1_6M', 'CHANNEL2_6M', 'CHANNEL3_6M', 'CHANNEL4_6M', 'CHANNEL5_6M', 'METHOD1_6M',\n",
    "          'RECENT_PAYMENT', 'PAYMENTS_6M']\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    for col in na_cols:\n",
    "        if math.isnan(float(row[col])):\n",
    "            median = data[col].median()\n",
    "            data[col].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5a2a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize outliers in numerical variables\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(5,5,1)\n",
    "fig = data.Tenure.hist(bins=10)\n",
    "fig.set_xlabel('Tenure')\n",
    "\n",
    "plt.subplot(5,5,2)\n",
    "fig = data.Age.hist(bins=10)\n",
    "fig.set_xlabel('Age')\n",
    "\n",
    "plt.subplot(5,5,3)\n",
    "fig = data.CHANNEL1_6M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL1_6M')\n",
    "\n",
    "plt.subplot(5,5,4)\n",
    "fig = data.CHANNEL2_6M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL2_6M')\n",
    "\n",
    "plt.subplot(5,5,5)\n",
    "fig = data.CHANNEL3_6M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL3_6M')\n",
    "\n",
    "plt.subplot(5,5,6)\n",
    "fig = data.CHANNEL4_6M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL4_6M')\n",
    "\n",
    "plt.subplot(5,5,7)\n",
    "fig = data.CHANNEL5_6M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL5_6M')\n",
    "\n",
    "plt.subplot(5,5,8)\n",
    "fig = data.METHOD1_6M.hist(bins=10)\n",
    "fig.set_xlabel('METHOD1_6M')\n",
    "\n",
    "plt.subplot(5,5,9)\n",
    "fig = data.RECENT_PAYMENT.hist(bins=10)\n",
    "fig.set_xlabel('RECENT_PAYMENT')\n",
    "\n",
    "plt.subplot(5,5,10)\n",
    "fig = data.PAYMENTS_6M.hist(bins=10)\n",
    "fig.set_xlabel('PAYMENTS_6M')\n",
    "\n",
    "plt.subplot(5,5,11)\n",
    "fig = data.CHANNEL1_3M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL1_3M')\n",
    "\n",
    "plt.subplot(5,5,12)\n",
    "fig = data.CHANNEL2_3M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL2_3M')\n",
    "\n",
    "plt.subplot(5,5,13)\n",
    "fig = data.CHANNEL3_3M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL3_3M')\n",
    "\n",
    "plt.subplot(5,5,14)\n",
    "fig = data.CHANNEL4_3M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL4_3M')\n",
    "\n",
    "plt.subplot(5,5,15)\n",
    "fig = data.CHANNEL5_3M.hist(bins=10)\n",
    "fig.set_xlabel('CHANNEL5_3M')\n",
    "\n",
    "plt.subplot(5,5,16)\n",
    "fig = data.METHOD1_3M.hist(bins=10)\n",
    "fig.set_xlabel('METHOD1_3M')\n",
    "\n",
    "plt.subplot(5,5,17)\n",
    "fig = data.PAYMENTS_3M.hist(bins=10)\n",
    "fig.set_xlabel('PAYMENTS_3M')\n",
    "\n",
    "plt.subplot(5,5,18)\n",
    "fig = data.NOT_DI_3M.hist(bins=10)\n",
    "fig.set_xlabel('NOT_DI_3M')\n",
    "\n",
    "plt.subplot(5,5,19)\n",
    "fig = data.NOT_DI_6M.hist(bins=10)\n",
    "fig.set_xlabel('NOT_DI_6M')\n",
    "\n",
    "plt.subplot(5,5,20)\n",
    "fig = data.EVENT1_30_FLAG.hist(bins=10)\n",
    "fig.set_xlabel('EVENT1_30_FLAG')\n",
    "\n",
    "plt.subplot(5,5,21)\n",
    "fig = data.EVENT2_90_SUM.hist(bins=10)\n",
    "fig.set_xlabel('EVENT2_90_SUM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe00c5",
   "metadata": {},
   "source": [
    "**Data Pre-Processing: Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802146b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify independent and target variables\n",
    "X = data.drop(['Call_Flag'], axis=1)\n",
    "y = data['Call_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view categorical variables in training dataset\n",
    "print(X[categorical_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables\n",
    "encoder = ce.BinaryEncoder(cols=['RTD_ST_CD', 'CustomerSegment', 'MART_STATUS', 'GENDER'])\n",
    "X = encoder.fit_transform(X)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c7d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SMOTE oversampling to address class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dad3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outliers\n",
    "def cap_outliers(columns):\n",
    "    for dat in [X_train, X_test]:\n",
    "        for col in columns:\n",
    "            IQR = dat[col].quantile(0.75) - dat[col].quantile(0.25)\n",
    "            lower = dat[col].quantile(0.25) - (1.5 * IQR)\n",
    "            upper = dat[col].quantile(0.75) + (1.5 * IQR)\n",
    "            print(f'{col} outliers are < {lower} and > {upper}.'.format(lower, upper))\n",
    "            \n",
    "            dat[col] = np.where(dat[col] > upper, upper, dat[col])\n",
    "        \n",
    "\n",
    "cols = ['CHANNEL1_6M', 'CHANNEL2_6M', 'CHANNEL3_6M', 'CHANNEL4_6M', 'CHANNEL5_6M',\n",
    "       'METHOD1_6M', 'RECENT_PAYMENT', 'PAYMENTS_6M', 'CHANNEL1_3M', 'CHANNEL2_3M',\n",
    "       'Tenure', 'Age', 'CHANNEL3_3M', 'CHANNEL4_3M', 'CHANNEL5_3M', 'METHOD1_3M',\n",
    "       'PAYMENTS_3M', 'NOT_DI_3M', 'NOT_DI_6M', 'EVENT1_30_FLAG', 'EVENT2_90_SUM']\n",
    "cap_outliers(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization with MinMaxScaler\n",
    "column_names = X_train.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=column_names)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e78428",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b66adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert values to tensors\n",
    "X_train = torch.tensor(X_train.values)\n",
    "X_test = torch.tensor(X_test.values)\n",
    "\n",
    "y_train = torch.tensor(y_train.values)\n",
    "y_test = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement neural network model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, act, dropout_rate):\n",
    "        super(NN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.layer2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.layer3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.output = nn.Linear(hidden_dim3, 1)\n",
    "        if act == 'relu':\n",
    "            self.act = nn.functional.relu\n",
    "        elif act == 'leaky_relu':\n",
    "            self.act = nn.functional.leaky_relu\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act(self.layer2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.act(self.layer3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = nn.functional.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d992d",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train NN based on passed values\n",
    "def train_NN(data, epochs, dim1, dim2, dim3, act, dropout, lr):\n",
    "    X_train = data[0]\n",
    "    X_test = data[1]\n",
    "    y_train = data[2]\n",
    "    y_test = data[3]\n",
    "    model = NN(input_dim, dim1, dim2, dim3, act, dropout)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    acc_list = []\n",
    "    f1_list = []\n",
    "    for i in range(epochs):\n",
    "        #if i % 10 ==0:\n",
    "        #    print(f'Epoch: {i}/{epochs}')\n",
    "        optimizer.zero_grad()\n",
    "        pred = model.forward(X_train.float())\n",
    "        loss = nn.functional.binary_cross_entropy(pred.squeeze(), y_train.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_test = model.forward(X_test.float())\n",
    "        pred_labels = (pred_test.squeeze() > 0.5).int()\n",
    "        val_loss = nn.functional.binary_cross_entropy(pred_test.squeeze(), y_test.float())\n",
    "        \n",
    "        acc_list.append(accuracy_score(y_test, pred_labels))\n",
    "        f1_list.append(f1_score(y_test, pred_labels))\n",
    "    \n",
    "    return([np.mean(acc_list), np.mean(f1_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate search space array for grid search\n",
    "def search_space(data, param_grid):\n",
    "    space_rows = 1\n",
    "    space_cols = len(param_grid) + 2\n",
    "    for key in param_grid:\n",
    "        space_rows *= len(param_grid[key])\n",
    "    space = np.zeros((space_rows, space_cols))\n",
    "    index = 0\n",
    "    for epochs in param_grid['epochs']:\n",
    "        for dim1 in param_grid['hidden_dim1']:\n",
    "            for dim2 in param_grid['hidden_dim2']:\n",
    "                for dim3 in param_grid['hidden_dim3']:\n",
    "                    for idx, act in enumerate(param_grid['act']):\n",
    "                        for drop in param_grid['dropout']:\n",
    "                            for lr in param_grid['lr']:\n",
    "                                print(f'Iteration: {index}/{space_rows}')\n",
    "                                result = train_NN(data, epochs, dim1, dim2, dim3, act, drop, lr)\n",
    "                                space[index] = np.array([epochs, dim1, dim2, dim3, idx, drop, lr, result[0], result[1]])\n",
    "                                index += 1\n",
    "    resultDf = pd.DataFrame(space, columns=['Epochs', 'Dim1', 'Dim2', 'Dim3',\n",
    "                                           'Activation', 'Dropout', 'LR', 'Acc', 'F1'])\n",
    "    return resultDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8952777e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform grid search based on possible values\n",
    "param_grid = dict(epochs=[100, 500, 1000], hidden_dim1=[32, 64],\n",
    "                 hidden_dim2=[16, 32], hidden_dim3=[8, 16],\n",
    "                 act=['relu', 'leaky_relu'], dropout=[0.1, 0.2],\n",
    "                 lr=[0.01, 0.001])\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "resultDf = search_space(data, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View maximum values\n",
    "resultDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ada1a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# View accuracies greater than 92%\n",
    "resultDf[resultDf['Acc'] > 0.92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d412d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform final training loop based on hyperparameters with best results from grid search\n",
    "epochs = 1000\n",
    "dim1 = 64\n",
    "dim2 = 16\n",
    "dim3 = 8\n",
    "activation = 'relu'\n",
    "dropout = 0.1\n",
    "lr = 0.01\n",
    "\n",
    "model = NN(input_dim, dim1, dim2, dim3, activation, dropout)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model.forward(X_train.float())\n",
    "    loss = nn.functional.binary_cross_entropy(pred.squeeze(), y_train.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item())\n",
    "    pred_test = model.forward(X_test.float())\n",
    "    pred_labels = (pred_test.squeeze() > 0.5).int()\n",
    "    val_loss = nn.functional.binary_cross_entropy(pred_test.squeeze(), y_test.float())\n",
    "    test_loss.append(val_loss.item())\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        accuracy = accuracy_score(y_test, pred_labels)\n",
    "        precision = precision_score(y_test, pred_labels, zero_division=0)\n",
    "        recall = recall_score(y_test, pred_labels)\n",
    "        f1 = f1_score(y_test, pred_labels)\n",
    "        \n",
    "        print(f'Epoch: {i}, Loss: {loss.item()}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63cf82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find test loss at final epoch\n",
    "test_loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report for model\n",
    "y_pred = model.forward(X_test.float())\n",
    "y_pred = y_pred.detach().numpy()\n",
    "for i, pred in enumerate(y_pred):\n",
    "    y_pred[i] = round(pred[0])\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area under ROC curve\n",
    "print(f'ROC AUC: {metrics.roc_auc_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "y_pred = model.forward(X_test.float())\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred.detach().numpy())\n",
    "\n",
    "roc_df = pd.DataFrame({\"False Positive Rate\": fpr, \"True Positive Rate\": tpr})\n",
    "\n",
    "fig = plt.subplots(figsize=(8, 5))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(x=\"False Positive Rate\", y=\"True Positive Rate\", data=roc_df, color='crimson')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train / loss curves\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(train_loss, label='Training Loss', color='crimson')\n",
    "sns.lineplot(test_loss, label='Validation Loss', color='midnightblue')\n",
    "\n",
    "ax.set(title='Train / Validation Loss', xlabel='Epochs', ylabel='Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
